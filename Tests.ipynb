{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5388d80e-cbc9-49a1-a7ce-0c835e590240",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 10:04:24.211469: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47405, 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras import backend as K\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "import os\n",
    "import time\n",
    "\n",
    "input_data = pd.read_csv(\"TRAINING_50K_input.csv\")\n",
    "output_data = pd.read_csv(\"TRAINING_50K_output.csv\")\n",
    "#time = np.linspace(0.0001, 0.5, num=5000)\n",
    "test = pd.read_csv(\"paper-test.csv\").to_numpy()\n",
    "X_test = test[:-1]\n",
    "Y_test = test[1:]\n",
    "feature_cols = [\"T\", \"Y_h\", \"Y_h2\", \"Y_o\", \"Y_o2\", \"Y_oh\", \"Y_h2o\", \"Y_ho2\", \"Y_h2o2\"]\n",
    "X = input_data[feature_cols].to_numpy()\n",
    "X_next = output_data[feature_cols].to_numpy()\n",
    "\n",
    "# Check for NaN values\n",
    "assert not np.any(np.isnan(X)), \"X contains NaN values\"\n",
    "assert not np.any(np.isnan(X_next)), \"y contains NaN values\"\n",
    "\n",
    "X, X_next = shuffle(X, X_next)\n",
    "\n",
    "t_test = np.linspace(0, 2500, 1)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65bd79cd-eba7-4425-8344-591df5164da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaseModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(16, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(32, activation='relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(16, activation='relu')\n",
    "        self.output_layer = tf.keras.layers.Dense(9)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        return self.output_layer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "533b9bb9-9c07-47d5-9295-08c12480cc54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DeepEnsemble:\n",
    "    def __init__(self, n_models=10, model_dir='saved_models'):\n",
    "        self.n_models = n_models\n",
    "        self.models = [BaseModel() for _ in range(n_models)]\n",
    "        self.model_dir = model_dir\n",
    "        self.state_dim = 9  # Define state dimension\n",
    "\n",
    "    def compile(self, optimizer='adam', loss='mse'):\n",
    "        for model in self.models:\n",
    "            model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "    def fit(self, dataset, epochs=500, verbose=0, callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)]):\n",
    "        for i, model in enumerate(self.models):\n",
    "            print(f'Training model {i+1}/{self.n_models}')\n",
    "            model.fit(dataset, epochs=epochs, verbose=verbose, callbacks=callbacks)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([model.predict(X, verbose=0) for model in self.models])\n",
    "        mean = np.mean(predictions, axis=0)\n",
    "        variance = np.var(predictions, axis=0)\n",
    "        return mean, variance\n",
    "    \n",
    "    def predict_iterative(self, initial_state, n_steps, include_variance=True):\n",
    "        \"\"\"\n",
    "        Perform iterative predictions starting from an initial state.\n",
    "        \n",
    "        Args:\n",
    "            initial_state: numpy array of shape (9,) containing the state variables\n",
    "            n_steps: number of time steps to predict\n",
    "            include_variance: whether to return variance estimates\n",
    "            \n",
    "        Returns:\n",
    "            predictions: numpy array of shape (n_steps, 9) containing state predictions\n",
    "            variances: numpy array of shape (n_steps, 9) containing variance estimates\n",
    "                      (only if include_variance=True)\n",
    "        \"\"\"\n",
    "        # Verify input dimension\n",
    "        if initial_state.shape != (self.state_dim,):\n",
    "            raise ValueError(f\"Initial state must have shape ({self.state_dim},), got {initial_state.shape}\")\n",
    "        \n",
    "        # Initialize arrays to store predictions and variances\n",
    "        predictions = np.zeros((n_steps, self.state_dim))\n",
    "        if include_variance:\n",
    "            variances = np.zeros((n_steps, self.state_dim))\n",
    "        \n",
    "        # Set initial state\n",
    "        current_state = initial_state.reshape(1, -1)  # Reshape to (1, 9) for model input\n",
    "        \n",
    "        # Perform iterative predictions\n",
    "        for step in range(n_steps):\n",
    "            # Get prediction and variance for current state\n",
    "            mean, variance = self.predict(current_state)\n",
    "            \n",
    "            # Store results\n",
    "            predictions[step] = mean[0]  # Remove batch dimension\n",
    "            if include_variance:\n",
    "                variances[step] = variance[0]\n",
    "            \n",
    "            # Update current state for next prediction\n",
    "            current_state = mean\n",
    "        \n",
    "        if include_variance:\n",
    "            return predictions, variances\n",
    "        return predictions\n",
    "    \n",
    "    def save_models(self, custom_dir=None):\n",
    "        \"\"\"Save all models in the ensemble\"\"\"\n",
    "        save_dir = custom_dir if custom_dir else self.model_dir\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        for i, model in enumerate(self.models):\n",
    "            model_path = os.path.join(save_dir, f'model_{i}')\n",
    "            model.save(model_path)\n",
    "        \n",
    "        metadata = {\n",
    "            'n_models': self.n_models,\n",
    "            'model_dir': save_dir,\n",
    "            'state_dim': self.state_dim\n",
    "        }\n",
    "        np.save(os.path.join(save_dir, 'metadata.npy'), metadata)\n",
    "        \n",
    "        print(f'Ensemble saved to {save_dir}')\n",
    "\n",
    "    @classmethod\n",
    "    def load_models(cls, model_dir):\n",
    "        \"\"\"Load a previously saved ensemble\"\"\"\n",
    "        if not os.path.exists(model_dir):\n",
    "            raise ValueError(f\"Directory {model_dir} does not exist\")\n",
    "            \n",
    "        metadata = np.load(os.path.join(model_dir, 'metadata.npy'), allow_pickle=True).item()\n",
    "        ensemble = cls(n_models=metadata['n_models'], model_dir=model_dir)\n",
    "        \n",
    "        ensemble.models = []\n",
    "        for i in range(metadata['n_models']):\n",
    "            model_path = os.path.join(model_dir, f'model_{i}')\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "            ensemble.models.append(model)\n",
    "            \n",
    "        print(f'Loaded ensemble from {model_dir}')\n",
    "        return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad5f6516-4bfe-421a-9618-d4d83746a39b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_results(t_test, x_test, mean, variance):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(t_test, x_test[:, 0], 'b-', label='True x')\n",
    "    plt.plot(t_test, mean[:, 0], 'r--', label='Predicted x')\n",
    "    plt.fill_between(t_test, mean[:, 0] - 2*np.sqrt(variance[:, 0]), \n",
    "                     mean[:, 0] + 2*np.sqrt(variance[:, 0]), color='r', alpha=0.2)\n",
    "    plt.xlabel('Time') \n",
    "    plt.ylabel('Temperature (K)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_iterative_results(predictions, variances=None, dt=0.1):\n",
    "    \"\"\"\n",
    "    Plot the results of iterative predictions for 9D state.\n",
    "    \n",
    "    Args:\n",
    "        predictions: numpy array of shape (n_steps, 9) containing state predictions\n",
    "        variances: numpy array of shape (n_steps, 9) containing variance estimates\n",
    "        dt: time step size for creating time array\n",
    "    \"\"\"\n",
    "    # Create time array\n",
    "    t = np.arange(len(predictions)) * dt\n",
    "    \n",
    "    # Calculate number of rows needed for 9 subplots (3x3 grid)\n",
    "    n_rows = 3\n",
    "    n_cols = 3\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 15))\n",
    "    \n",
    "    # Flatten axes for easier iteration\n",
    "    axes_flat = axes.flatten()\n",
    "    \n",
    "    # Plot each state variable\n",
    "    for i in range(9):\n",
    "        ax = axes_flat[i]\n",
    "        \n",
    "        # Plot predictions\n",
    "        ax.plot(t, predictions[:, i], 'b-', label=f'State {i+1}')\n",
    "        \n",
    "        # Add uncertainty bounds if available\n",
    "        if variances is not None:\n",
    "            ax.fill_between(t,\n",
    "                          predictions[:, i] - 2*np.sqrt(variances[:, i]),\n",
    "                          predictions[:, i] + 2*np.sqrt(variances[:, i]),\n",
    "                          color='b', alpha=0.2)\n",
    "        \n",
    "        # Customize subplot\n",
    "        ax.set_xlabel('Time Step')\n",
    "        ax.set_ylabel(f'State {i+1}')\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_state_correlation(predictions, state_indices, dt=0.1):\n",
    "    \"\"\"\n",
    "    Plot correlation between two selected state variables.\n",
    "    \n",
    "    Args:\n",
    "        predictions: numpy array of shape (n_steps, 9) containing state predictions\n",
    "        state_indices: tuple of two integers specifying which states to plot\n",
    "        dt: time step size for creating time array\n",
    "    \"\"\"\n",
    "    i, j = state_indices\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(predictions[:, i], predictions[:, j], 'b-')\n",
    "    plt.xlabel(f'State {i+1}')\n",
    "    plt.ylabel(f'State {j+1}')\n",
    "    plt.title(f'State {i+1} vs State {j+1}')\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48213350-7e56-4b20-b151-7cae1bd7eb67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_iterative_results(predictions, variances=None, dt=0.1):\n",
    "    \"\"\"\n",
    "    Plot the results of iterative predictions for 9D state.\n",
    "    \n",
    "    Args:\n",
    "        predictions: numpy array of shape (n_steps, 9) containing state predictions\n",
    "        variances: numpy array of shape (n_steps, 9) containing variance estimates\n",
    "        dt: time step size for creating time array\n",
    "    \"\"\"\n",
    "    # Create time array\n",
    "    t = np.arange(len(predictions)) * dt\n",
    "    \n",
    "    # Calculate number of rows needed for 9 subplots (3x3 grid)\n",
    "    n_rows = 3\n",
    "    n_cols = 3\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 15))\n",
    "    \n",
    "    # Flatten axes for easier iteration\n",
    "    axes_flat = axes.flatten()\n",
    "    \n",
    "    # Plot each state variable\n",
    "    for i in range(9):\n",
    "        ax = axes_flat[i]\n",
    "        \n",
    "        # Plot predictions\n",
    "        ax.plot(t, predictions[:, i], 'b-', label=f'State {i+1}')\n",
    "        \n",
    "        # Add uncertainty bounds if available\n",
    "        if variances is not None:\n",
    "            ax.fill_between(t,\n",
    "                          predictions[:, i] - 2*np.sqrt(variances[:, i]),\n",
    "                          predictions[:, i] + 2*np.sqrt(variances[:, i]),\n",
    "                          color='b', alpha=0.2)\n",
    "        \n",
    "        # Customize subplot\n",
    "        ax.set_xlabel('Time Step')\n",
    "        ax.set_ylabel(f'State {i+1}')\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_state_correlation(predictions, state_indices, dt=0.1):\n",
    "    \"\"\"\n",
    "    Plot correlation between two selected state variables.\n",
    "    \n",
    "    Args:\n",
    "        predictions: numpy array of shape (n_steps, 9) containing state predictions\n",
    "        state_indices: tuple of two integers specifying which states to plot\n",
    "        dt: time step size for creating time array\n",
    "    \"\"\"\n",
    "    i, j = state_indices\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(predictions[:, i], predictions[:, j], 'b-')\n",
    "    plt.xlabel(f'State {i+1}')\n",
    "    plt.ylabel(f'State {j+1}')\n",
    "    plt.title(f'State {i+1} vs State {j+1}')\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc30fa7c-5e84-4608-ab25-901248c4bd14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, X_next)).shuffle(47405).batch(32)\n",
    "    ensemble = DeepEnsemble(n_models=10)\n",
    "    ensemble.compile()\n",
    "    ensemble.fit(dataset)\n",
    "\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de08d20-42e8-4b39-b690-15f2a7893c23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, Y_test):\n",
    "    mean, variance = model.predict(X_test)\n",
    "    mse = np.mean((Y_test - mean)**2)\n",
    "    uncertainty = np.mean(np.sqrt(variance))\n",
    "    return mse, uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a22ff35-f440-4899-9f35-81d15549fe59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing model found. Training new ensemble...\n",
      "Training model 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 10:04:28.648135: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 10:15:33.669815: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 43791 of 47405\n",
      "2024-11-01 10:15:36.162335: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2024-11-01 10:22:07.909595: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 43402 of 47405\n",
      "2024-11-01 10:22:08.147873: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2024-11-01 10:22:33.640888: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 43616 of 47405\n",
      "2024-11-01 10:22:34.713655: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2024-11-01 10:24:33.583006: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 45142 of 47405\n",
      "2024-11-01 10:24:36.557668: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2024-11-01 10:24:47.746694: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 44868 of 47405\n",
      "2024-11-01 10:24:50.763148: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2024-11-01 10:28:08.572053: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 45416 of 47405\n",
      "2024-11-01 10:28:08.807959: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2024-11-01 10:31:02.144349: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 46448 of 47405\n",
      "2024-11-01 10:31:02.368660: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2024-11-01 10:35:18.743869: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 47074 of 47405\n",
      "2024-11-01 10:35:18.968343: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 3/10\n",
      "Training model 4/10\n",
      "Training model 5/10\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    #X, X_next, X_test, Y_test, t_test = import_data()\n",
    "    # Define paths\n",
    "    saved_model_path = 'my_saved_ensemble'\n",
    "\n",
    "    # Check for existing model\n",
    "    if not os.path.exists(saved_model_path):\n",
    "        print(\"No existing model found. Training new ensemble...\")\n",
    "        try:\n",
    "            # Train the model using train_model()\n",
    "            ensemble = train_model()\n",
    "            \n",
    "            # Save the trained ensemble\n",
    "            print(\"Training complete. Saving model...\")\n",
    "            ensemble.save_models(saved_model_path)\n",
    "            print(f\"Model saved to {saved_model_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during training: {str(e)}\")\n",
    "            return\n",
    "    else:\n",
    "        # Load the trained model\n",
    "        print(\"Loading existing ensemble...\")\n",
    "        try:\n",
    "            ensemble = DeepEnsemble.load_models(saved_model_path)\n",
    "            print(\"Ensemble loaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {str(e)}\")\n",
    "            return\n",
    "\n",
    "    # Define initial condition (9-dimensional state)\n",
    "    initial_state = X[0, :]\n",
    "    \n",
    "    # Perform iterative predictions\n",
    "    n_steps = 250\n",
    "    print(f\"Performing iterative predictions for {n_steps} steps...\")\n",
    "    try:\n",
    "        predictions, variances = ensemble.predict_iterative(initial_state, n_steps=n_steps)\n",
    "        \n",
    "        # Visualize the results\n",
    "        print(\"Plotting results...\")\n",
    "        plot_iterative_results(predictions, variances, dt=0.1)\n",
    "        plot_state_correlation(predictions, (0, 1))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction or plotting: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f35ff51-6a80-404e-9b48-d891beeca662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_test = np.linspace(0, 1, 2499)\n",
    "test = pd.read_csv(\"paper-test.csv\").to_numpy()\n",
    "X_test = test[:-1]\n",
    "Y_test = test[1:]\n",
    "def plot_results(t_test, x_test, mean, variance):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(t_test.T, x_test[:, 0], 'b-', label='True x')\n",
    "    plt.plot(t_test.T, mean[:, 0], 'r--', label='Predicted x')\n",
    "    plt.fill_between(t_test, mean[:, 0] - 2*np.sqrt(variance[:, 0]), \n",
    "                     mean[:, 0] + 2*np.sqrt(variance[:, 0]), color='r', alpha=0.2)\n",
    "    plt.xlabel('Time') \n",
    "    plt.ylabel('Temperature (K)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b9253-cb2f-4960-885f-58299945f20d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_results(t_test, X_test, mean, variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c7482-f0c8-4cd5-ae00-c514d6704c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(t_test.T, X_test[:, 8], 'b-', label='True x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a2b7f5-16d4-4548-88e0-ca26b063610d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
